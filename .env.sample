################################################################################
# ClinicTech RAG - Environment Configuration Sample
# 
# Copy this file to .env and update with your actual values
# DO NOT commit .env file to git (it contains sensitive API keys)
################################################################################

################################################################################
# 1. FASTAPI CONFIGURATION
################################################################################

# Environment type: development, staging, production
FASTAPI_ENV=development

# API host and port
API_HOST=0.0.0.0
API_PORT=8000

# Debug mode (disable in production)
DEBUG=True


################################################################################
# 2. LLM CONFIGURATION (Required for answer generation)
################################################################################

# LLM Provider: openai or anthropic
LLM_PROVIDER=openai

# LLM Model
# OpenAI: gpt-4-turbo, gpt-4, gpt-3.5-turbo
# Anthropic: claude-3-opus, claude-3-sonnet, claude-3-haiku
LLM_MODEL=gpt-4-turbo

# OpenAI API Key - Get from https://platform.openai.com/api-keys
# Format: sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
LLM_API_KEY=sk-proj-YOUR_OPENAI_API_KEY_HERE

# LLM Temperature (0.0 = deterministic, 1.0 = creative)
# Use 0.1 for medical documents (strict grounding)
LLM_TEMPERATURE=0.1

# Maximum tokens for LLM response
LLM_MAX_TOKENS=2000


################################################################################
# 3. EMBEDDING CONFIGURATION (Required for semantic search)
################################################################################

# Embedding Model
# text-embedding-3-small: 1536 dimensions (recommended, fast)
# text-embedding-3-large: 3072 dimensions (more accurate, slower)
# text-embedding-ada-002: 1536 dimensions (legacy)
EMBEDDING_MODEL=text-embedding-3-small

# Embedding API Key (same as LLM for OpenAI)
EMBEDDING_API_KEY=sk-proj-YOUR_OPENAI_API_KEY_HERE

# Embedding vector dimension (must match model)
# text-embedding-3-small: 1536
# text-embedding-3-large: 3072
EMBEDDING_DIMENSION=1536


################################################################################
# 4. PDF PROCESSING & OCR CONFIGURATION
################################################################################

# OCR Provider: tesseract (only option for now)
OCR_PROVIDER=tesseract

# Path to Tesseract OCR executable
# Windows: C:\Program Files\Tesseract-OCR\tesseract.exe
# Linux: /usr/bin/tesseract
# macOS: /usr/local/bin/tesseract
TESSERACT_PATH=C:\Program Files\Tesseract-OCR\tesseract.exe


################################################################################
# 5. TEXT CHUNKING CONFIGURATION
################################################################################

# Size of each text chunk (characters)
# Recommended: 500 for medical documents
CHUNK_SIZE=500

# Overlap between chunks (characters)
# Recommended: 100 (20% overlap)
CHUNK_OVERLAP=100

# Maximum length of metadata per chunk
MAX_METADATA_LENGTH=200


################################################################################
# 6. RETRIEVAL & RERANKING CONFIGURATION
################################################################################

# Number of top chunks to retrieve
# Recommended: 5-10
TOP_K_RESULTS=5

# Cross-encoder model for relevance reranking
# Recommended: cross-encoder/mmarco-MiniLMv2-L12-H384-v1
RERANK_MODEL=cross-encoder/mmarco-MiniLMv2-L12-H384-v1

# Minimum similarity threshold for retrieval
# Range: 0.0-1.0
# Recommended: 0.5
SIMILARITY_THRESHOLD=0.5


################################################################################
# 7. VERIFICATION & SAFETY CONFIGURATION
################################################################################

# Enable post-answer verification (grounding, consistency, relevance)
VERIFICATION_ENABLED=True

# Minimum confidence score to return answer (0.0-1.0)
# Recommended: 0.7
CONFIDENCE_THRESHOLD=0.7


################################################################################
# 8. STORAGE CONFIGURATION
################################################################################

# Root storage directory
STORAGE_PATH=./storage

# Logs directory
LOG_PATH=./logs

# Maximum file upload size (bytes)
# Default: 52428800 (50MB)
UPLOAD_MAX_SIZE=52428800


################################################################################
# 9. VECTOR DATABASE CONFIGURATION
################################################################################

# Vector database type: chroma, milvus, pinecone
VECTOR_DB_TYPE=chroma

# Vector database path (for local DBs like Chroma)
VECTOR_DB_PATH=./storage/chroma_db

# Vector database URL (for remote DBs)
# Milvus example: http://localhost:19530
# Pinecone: https://your-index-name-xxxxx.svc.pinecone.io
VECTOR_DB_URL=http://localhost:19530


################################################################################
# 10. DATABASE CONFIGURATION (Optional - for future SQL storage)
################################################################################

# PostgreSQL connection URL (optional)
DATABASE_URL=postgresql://user:password@localhost:5432/rag_db


################################################################################
# 11. REDIS CACHE CONFIGURATION (Optional - for caching)
################################################################################

# Redis server URL
REDIS_URL=redis://localhost:6379/0

# Cache time-to-live (seconds)
CACHE_TTL=3600

