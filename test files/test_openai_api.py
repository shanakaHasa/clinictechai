#!/usr/bin/env python3
"""Test OpenAI API v1.0.0+ compatibility"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

print("üîç Testing OpenAI API v1.0.0+ Compatibility")
print("=" * 60)

try:
    print("1Ô∏è‚É£  Loading settings...")
    from app.config.settings import settings
    print(f"   ‚úÖ LLM Provider: {settings.llm_provider}")
    print(f"   ‚úÖ LLM Model: {settings.llm_model}")
    
    print("\n2Ô∏è‚É£  Testing OpenAI Client (v1.0.0+)...")
    from openai import OpenAI
    client = OpenAI(api_key=settings.llm_api_key)
    print(f"   ‚úÖ OpenAI client created with new API")
    
    print("\n3Ô∏è‚É£  Testing chat.completions.create() method...")
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are helpful assistant."},
            {"role": "user", "content": "Say 'Hello from OpenAI v1.0.0+'"}
        ],
        temperature=0.1,
        max_tokens=50
    )
    print(f"   ‚úÖ API call successful!")
    print(f"   ‚úÖ Response: {response.choices[0].message.content}")
    print(f"   ‚úÖ Tokens used: {response.usage.total_tokens}")
    
    print("\n4Ô∏è‚É£  Testing LLM Service...")
    from app.llm.llm_service import LLMService
    llm_service = LLMService()
    
    if llm_service.client:
        print(f"   ‚úÖ LLM Service initialized")
        print(f"      - Provider: {llm_service.provider}")
        print(f"      - Model: {llm_service.model}")
        print(f"      - Temperature: {llm_service.temperature}")
    else:
        print(f"   ‚ùå LLM Service client not initialized")
    
    print("\n" + "=" * 60)
    print("‚úÖ ALL TESTS PASSED - OpenAI v1.0.0+ Compatible!")
    print("=" * 60)
    
except Exception as e:
    print(f"\n‚ùå ERROR: {str(e)}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
