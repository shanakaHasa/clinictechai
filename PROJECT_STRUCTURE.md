# FastAPI RAG Application - Project Structure Summary

## ğŸ“ Complete Directory Structure

```
clinictechai/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                          â­ FastAPI application entry point
â”œâ”€â”€ ğŸ“„ .env                             â­ Environment configuration (UPDATE WITH YOUR KEYS)
â”œâ”€â”€ ğŸ“„ .gitignore                       Git ignore file
â”œâ”€â”€ ğŸ“„ requirements.txt                 â­ Python dependencies
â”‚
â”œâ”€â”€ ğŸ“– README.md                        Project overview & architecture
â”œâ”€â”€ ğŸ“– QUICKSTART.md                    Quick start guide
â”œâ”€â”€ ğŸ“– ARCHITECTURE.md                  Detailed architecture & data flow
â”œâ”€â”€ ğŸ“– EXAMPLES.md                      Usage examples & patterns
â”‚
â”œâ”€â”€ ğŸ“ app/                             Main application package
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                  Package initialization
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ config/                      Configuration management
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ settings.py              â­ Pydantic settings (loads from .env)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ data_ingest/                 Layer 1: Document Ingestion
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ ingester.py              Upload, validate, store documents
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ pdf_processing/              Layer 2: PDF Type Detection
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ processor.py             Detect TEXT vs SCANNED PDFs
â”‚   â”‚   â””â”€â”€ ğŸ“„ ocr_processor.py         OCR pipeline for scanned PDFs
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ chunking/                    Layer 3: Text Chunking
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ chunker.py               Split text, preserve metadata
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ embedding/                   Layer 4: Embedding & Vector Store
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ embedding_service.py     Embeddings + vector DB operations
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ retrieval/                   Layer 5: Retrieval & Reranking
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ retriever.py             Vector search + cross-encoder reranking
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ llm/                         Layer 6: LLM Integration
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ llm_service.py           Grounded answer generation (strict mode)
â”‚   â”‚   â””â”€â”€ ğŸ“„ prompts.py               Optimized prompts for medical documents
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ safety/                      Layer 7: Content Moderation & Safety
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ content_moderator.py     OpenAI moderation API for hate speech filtering
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ verification/                Layer 8: Post-Answer Verification
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ verifier.py              Verify grounding & confidence scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ schemas/                     Data Validation
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ models.py                â­ Pydantic request/response models
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ utils/                       Utilities
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ helpers.py               Logging, ID generation, file utilities
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ api/                         API Routes
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â””â”€â”€ ğŸ“„ routes.py                â­ FastAPI endpoints (upload, query, health)
â”‚
â”œâ”€â”€ ğŸ“ storage/                         Document storage (auto-created)
â”‚   â”œâ”€â”€ ğŸ“ raw_documents/               Original PDF files
â”‚   â””â”€â”€ ğŸ“ processed_documents/         Processed content
â”‚
â””â”€â”€ ğŸ“ logs/                            Application logs (auto-created)
```

## ğŸ”„ Data Flow Pipeline

### Document Upload Flow
```
PDF File Upload
    â†“
Document Ingestion (data_ingest/ingester.py)
    â†“
PDF Type Detection (pdf_processing/processor.py)
    â”œâ”€â†’ TEXT â†’ Direct extraction (PyMuPDF)
    â””â”€â†’ SCANNED â†’ OCR Pipeline (pdf_processing/ocr_processor.py)
    â†“
Text Chunking (chunking/chunker.py)
    [Preserve: page_number, bbox, document_id]
    â†“
Embedding Generation (embedding/embedding_service.py)
    [1536-dimensional vectors]
    â†“
Vector Store (embedding/embedding_service.py)
    [Milvus/Pinecone/Chroma]
```

### Query Flow
```
User Query
    â†“
Retrieval (retrieval/retriever.py)
    [Vector similarity search]
    â†“
Reranking (retrieval/retriever.py)
    [Cross-encoder relevance scoring]
    â†“
LLM Answer Generation (llm/llm_service.py)
    [STRICT GROUNDED MODE - only use context]
    â†“
Post-Answer Verification (verification/verifier.py)
    [Grounding, consistency, relevance checks]
    â†“
Response with Evidence & Confidence Scores
    [Answer + Page Numbers + Evidence Chunks + Verification]
```

## ğŸ¯ 8-Layer Architecture

| Layer | Module | Purpose | Output |
|-------|--------|---------|--------|
| 1 | data_ingest | Upload & store documents | document_id, storage_path |
| 2 | pdf_processing | Detect PDF type | TEXT/SCANNED classification |
| 3 | (ocr_processor) | Extract from scanned PDFs | OCR text + confidence |
| 4 | chunking | Split & preserve metadata | Chunks with page/bbox/doc info |
| 5 | embedding | Generate vectors | 1536-dim embeddings + storage |
| 6 | retrieval | Vector search + rerank | Top-k relevant chunks |
| 7 | llm | Generate grounded answer | Factual answer text (no sources) |
| 8 | safety | Content moderation | Policy violation detection |
| 9 | verification | Verify quality | Confidence scores + evidence |
| - | api | HTTP endpoints | REST interface |

## ğŸ“‹ Key Files to Update/Configure

### 1. **FIRST: Update `.env`** (REQUIRED)
```bash
# Add your API keys
LLM_API_KEY=your_openai_or_anthropic_key
EMBEDDING_API_KEY=your_api_key_if_needed

# If using Tesseract OCR
TESSERACT_PATH=/path/to/tesseract

# Database URLs
DATABASE_URL=postgresql://...
VECTOR_DB_URL=http://localhost:19530
```

### 2. **Configure `app/config/settings.py`**
Already set up - just update `.env` file

### 3. **Main Entry Point: `main.py`**
Ready to run - no changes needed

### 4. **API Routes: `app/api/routes.py`**
Contains 3 endpoints:
- `POST /api/v1/upload` - Upload PDF
- `POST /api/v1/query` - Query RAG
- `GET /api/v1/health` - Health check

## ğŸš€ Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Update .env with your API keys
# Edit: .env file

# 3. Start application
python main.py

# 4. Open browser
# http://localhost:8000/docs
# (Interactive API documentation)
```

## ğŸ“Š Response Structure

Every RAG query returns:
```json
{
  "answer": "Grounded response based on documents",
  "page_numbers": [1, 3, 5],
  "evidence": [
    {
      "page_number": 1,
      "exact_chunk": "Quote from document",
      "bbox": [x0, y0, x1, y1],
      "highlighted": "Key terms highlighted"
    }
  ],
  "verification": {
    "confidence_score": 0.85,
    "grounding_score": 0.90,
    "consistency_score": 0.88,
    "relevance_score": 0.78
  },
  "sources": [
    {
      "document": "filename.pdf",
      "page_number": 1,
      "similarity_score": 0.92
    }
  ]
}
```

## âœ¨ Features Implemented

âœ… **Multi-Layer Architecture** - 7 distinct processing layers  
âœ… **PDF Type Detection** - Automatic TEXT/SCANNED classification  
âœ… **OCR Support** - Tesseract integration for scanned PDFs  
âœ… **Metadata Preservation** - Page numbers, bounding boxes, document refs  
âœ… **Semantic Chunking** - Overlapping chunks with context preservation  
âœ… **Vector Search** - Multiple backend support (Milvus, Pinecone, Chroma)  
âœ… **Reranking** - Cross-encoder relevance scoring  
âœ… **Grounded LLM** - Strict mode, no hallucination  
âœ… **Answer Verification** - 3-layer verification with confidence  
âœ… **Evidence Extraction** - Exact chunks with highlighting  

## ğŸ”§ Configuration Parameters

Key settings in `.env`:

```bash
# Chunking
CHUNK_SIZE=500              # Characters per chunk
CHUNK_OVERLAP=100           # Overlap between chunks

# Retrieval
TOP_K_RESULTS=5             # Results to retrieve
SIMILARITY_THRESHOLD=0.5    # Minimum similarity

# LLM
LLM_TEMPERATURE=0.1         # Low = grounded, high = creative
LLM_MAX_TOKENS=2000         # Max response length

# Verification
VERIFICATION_ENABLED=True
CONFIDENCE_THRESHOLD=0.7    # Minimum confidence

# Embedding
EMBEDDING_DIMENSION=1536    # Vector dimensions
EMBEDDING_MODEL=text-embedding-3-small
```

## ğŸ“š Documentation Files

| File | Purpose |
|------|---------|
| README.md | Project overview & architecture |
| QUICKSTART.md | Quick start guide (40+ lines) |
| ARCHITECTURE.md | Detailed data flow & design |
| EXAMPLES.md | 9 usage examples with code |
| QUICKSTART.py | (This file) - Structure reference |

## ğŸ“ Learning Path

1. **Start**: Read README.md
2. **Setup**: Follow QUICKSTART.md
3. **Understand**: Read ARCHITECTURE.md  
4. **Practice**: Try examples in EXAMPLES.md
5. **Deploy**: Update .env and run `python main.py`

## ğŸ” Module Relationships

```
main.py (FastAPI app)
    â†“
app/api/routes.py (Endpoints)
    â”œâ†’ data_ingest/ingester.py (Upload)
    â”œâ†’ pdf_processing/processor.py (Detect type)
    â”œâ†’ pdf_processing/ocr_processor.py (OCR if needed)
    â”œâ†’ chunking/chunker.py (Split text)
    â”œâ†’ embedding/embedding_service.py (Vectorize)
    â”œâ†’ retrieval/retriever.py (Search + rerank)
    â”œâ†’ llm/llm_service.py (Generate answer)
    â”œâ†’ verification/verifier.py (Verify quality)
    â””â†’ schemas/models.py (Validate data)

All configured via:
    app/config/settings.py â† .env file
```

## ğŸ¯ Ready for:

- âœ… Medical document processing
- âœ… PDF knowledge base
- âœ… Clinical decision support
- âœ… Document Q&A systems
- âœ… Evidence-based information retrieval

## ğŸ“ Next Steps

1. Update `.env` with your API keys
2. Run `pip install -r requirements.txt`
3. Start with `python main.py`
4. Visit `http://localhost:8000/docs` for interactive API testing
5. Upload a PDF and ask questions!
